run_id: comparative-1-iter1-Qwen3-0.6B-gsm8k
method: comparative-1
model:
  name: Qwen/Qwen3-0.6B
  precision: fp16
  parameter_update_modes: [FULL, FROZEN]  # HiCaP-DF (no LoRA)
  gradient_checkpointing: true
dataset:
  name: gsm8k
  split: train
  max_length: 1024
  batch_size: 8
  grad_accumulation_steps: 8
  num_epochs: 1
training:
  base_learning_rate: 2.0e-4   # tuned by Optuna
  optimizer: adamw
  betas: [0.9, 0.95]
  eps: 1.0e-8
  weight_decay: 0.01
  scheduler: none              # HiCaP controls LR internally
  max_steps: 1180
  pid_gains:
    global: {Kp: 1.2, Ki: 0.1, Kd: 0.0}
    layer:  {Kp: 0.35, Ki: 0.05}
  freeze_controller:
    thresholds:
      full_to_frozen: 0.15     # × r*_ℓ
      recover_to_full: 0.35
      patience_full_to_frozen: 30
logging:
  interval_steps: 20
  holdout_interval_steps: 50
  log_metrics: [loss, exact_match_holdout, backward_flops, cumulative_energy, per_layer_mode]
checkpointing:
  save_every_steps: 200
  output_dir: checkpoints/hicap_df
environment:
  device: cuda
  gpu_type: a100-80gb
optuna:
  n_trials: 25
  direction: maximize
  search_space:
    base_learning_rate:
      type: loguniform
      low: 1.0e-5
      high: 5.0e-4
    weight_decay:
      type: loguniform
      low: 1.0e-4
      high: 1.0e-2
    freeze_controller.thresholds.full_to_frozen:
      type: uniform
      low: 0.12
      high: 0.25
    freeze_controller.thresholds.patience_full_to_frozen:
      type: int
      low: 20
      high: 50
    grad_accumulation_steps:
      type: categorical
      choices: [4, 8, 16]
